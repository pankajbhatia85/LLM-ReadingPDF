{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7150,
     "status": "ok",
     "timestamp": 1692662055889,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "q1qD2ZDya5OV",
    "outputId": "5bdeb273-f191-4abc-f0d1-4f0ba8491e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.270)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
      "Requirement already satisfied: pyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.25)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.2.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.31.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai faiss-cpu pyPDF2 sentence-transformers\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9532,
     "status": "ok",
     "timestamp": 1692662068528,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "-6m-yx8ubJBw",
    "outputId": "f0296e89-0b8e-4027-990f-21c192a04351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1692662068530,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "oA2Cg2XgcV7i"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.vectorstores import FAISS,faiss\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings,HuggingFaceInstructEmbeddings,HuggingFaceHubEmbeddings,OpenAIEmbeddings,HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain.chains import QAWithSourcesChain,RetrievalQA\n",
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import openai\n",
    "import faiss\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1692662068530,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "xdbZ8YXMgwij"
   },
   "outputs": [],
   "source": [
    "My_pdf=PdfReader(\"/content/Tenable_Vulnerability_Management-User_Guide.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1692662068531,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "TZjOG3RYzIEw"
   },
   "outputs": [],
   "source": [
    "page_tot=len(My_pdf.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1692662074836,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "rjm8y1C4sFfT"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def prepare_data(data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100,length_function=len,separators='\\n')\n",
    "    processed_data = []\n",
    "#     print(data)\n",
    "#     value , text = data\n",
    "    for text , value in tqdm(data):\n",
    "        #cleaning of text\n",
    "#         text = text.replace('\\n' , '')\n",
    "#         text = text.replace('-' , '')\n",
    "#         text = text.replace('.' , '')\n",
    "#         text = replace_multiple_spaces_with_single_space(text)\n",
    "        splits = text_splitter.split_text(text)\n",
    "        processed_data.extend(\n",
    "            [\n",
    "                Document(\n",
    "                    page_content= texts,\n",
    "                    metadata={\"source\": value}\n",
    "                ) for texts in splits\n",
    "            ]\n",
    "        )\n",
    "#         time.sleep(3)\n",
    "#     print(len(processed_data))\n",
    "#     for i in processed_data:\n",
    "#         print(i.metadata)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "executionInfo": {
     "elapsed": 120525,
     "status": "ok",
     "timestamp": 1692662196974,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "WkiFTvdSiXNy"
   },
   "outputs": [],
   "source": [
    "extract_data=[]\n",
    "for page_num in range (page_tot):\n",
    "  page=My_pdf.pages[page_num]\n",
    "  content=page.extract_text()\n",
    "  extract_data.append((str(content),str(page_num+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1692662196982,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "F2IPQoUlsF40",
    "outputId": "9fe0875b-6441-434c-93db-5753e7de484c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2278/2278 [00:00<00:00, 9935.21it/s] \n"
     ]
    }
   ],
   "source": [
    "final_data=prepare_data(extract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1692662196984,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "TWucwA8OvoQu",
    "outputId": "8122aa83-1dd6-4116-a2f1-274e62909834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"scantargetlimitis,orwouldliketoincrease thelimit,contactTenable\\nSupport.\\nScanresultsper\\nscanTenableVulnerability Management limitsthenumberofscanresultsthat\\nasinglescancangenerate. Thescanresultslimitisapproximately 110%\\nofyourorganization's licensed assetcount.\\nForexample, ifyourorganization hasalicensed assetcountof1,000,Ten-\\nableVulnerability Management doesnotallowyoutogenerate morethan\\n1,100scanresultsfromasinglescan.Ifyouexceedthelimit,TenableVul-\\nnerability Management abortsthescan.TenableVulnerability Man-\\nagement doesnotapplythescanresultlimittodiscovery scans.Ifyou\\n-125-\", metadata={'source': '125'})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " final_data[187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1692662212286,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "KAzZyNA0_c5l"
   },
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs = {'device': 'cuda'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1692662213820,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "aAHbd5YR7xax"
   },
   "outputs": [],
   "source": [
    "from langchain import embeddings\n",
    "def create_index1(data, save_path):\n",
    "    docs = prepare_data(data=data)\n",
    "    docsearch = FAISS.from_documents(docs, embedding)             #This part is vectorstore using FAISS\n",
    "    docsearch.save_local(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9592,
     "status": "ok",
     "timestamp": 1692662326933,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "sPDIK2t2BXxH",
    "outputId": "2f7df089-af9d-4a3c-ee6f-2eee1a3c84f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2278/2278 [00:00<00:00, 9797.62it/s] \n"
     ]
    }
   ],
   "source": [
    "save_path=\"/content/drive/MyDrive/Colab Notebooks/PDF_Read_FAISS/my_index\"\n",
    "faiss_index=create_index1(extract_data,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1692662339985,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "YDXPKwwMCibY"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1692662342806,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "mvrB8vPkJrmT"
   },
   "outputs": [],
   "source": [
    "def load_model(output_path: str):\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(\n",
    "            openai_api_key=openai.api_key,\n",
    "            temperature=0.85, model_name=\"gpt-3.5-turbo\", max_tokens=1024,\n",
    "        ),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=FAISS.load_local(output_path, embedding)      #We are loading the saved index, retriever= db.as_retriever()\n",
    "            .as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5} )     #This is retriever\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1692662345604,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "B_-JmkVpX_Nl"
   },
   "outputs": [],
   "source": [
    "chatbot=load_model(output_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4068,
     "status": "ok",
     "timestamp": 1692662352433,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "7K3EnB8EYTps",
    "outputId": "d8539607-3db5-4a21-aa3e-61187c80cdd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To deploy Tenable Web App Scanning as a Docker image, you can follow these steps:\n",
      "\n",
      "1. Download and install Docker for your operating system.\n",
      "\n",
      "2. Access the Tenable Web App Scanning Docker image from the Tenable Docker Hub repository: https://hub.docker.com/r/tenable/was-scanner.\n",
      "\n",
      "3. Use the appropriate operators with the desired options for your deployment, as described in the documentation.\n",
      "\n",
      "4. Set environment variables using the \"-e\" operator to configure Tenable Web App Scanning during the deployment.\n",
      "\n",
      "Please note that Tenable Web App Scanning does not have a command-line interface or configuration wizard, so you need to use environment variables to configure it. Also, be aware that the Tenable Web App Scanning Docker image only works on AMD64-bit systems and does not support ARM or Windows systems.\n",
      "\n",
      "Before starting the deployment, make sure you have Docker installed and access to the Tenable Web App Scanning Docker image.\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.run(\"how to Deploy Tenable Web App Scanning as a Docker Image\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2981,
     "status": "ok",
     "timestamp": 1692662356637,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "2yB4ZperaAWj",
    "outputId": "41f29f95-bcfa-4949-847d-3ed08e245313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To deploy Tenable Web App Scanning as a Docker image, you can use the following commands:\n",
      "\n",
      "1. Build the Docker image:\n",
      "\n",
      "```shell\n",
      "$ docker build -t <image-name> .\n",
      "```\n",
      "\n",
      "2. Log in to the Docker registry:\n",
      "\n",
      "```shell\n",
      "$ docker login -u <TENABLE_IO_ACCESS_KEY> -p <TENABLE_IO_SECRET_KEY> registry.cloud.tenable.com\n",
      "```\n",
      "\n",
      "3. Push the Docker image to the registry:\n",
      "\n",
      "```shell\n",
      "$ docker push <image-name>\n",
      "```\n",
      "\n",
      "Note: Replace `<image-name>` with the desired name for your Docker image. Also, make sure to replace `<TENABLE_IO_ACCESS_KEY>` and `<TENABLE_IO_SECRET_KEY>` with your Tenable.io access key and secret key respectively.\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.run(\"commands Deploy Tenable Web App Scanning as a Docker Image\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1692662360522,
     "user": {
      "displayName": "Pankaj Bhatia",
      "userId": "16748094277534649498"
     },
     "user_tz": 420
    },
    "id": "xHc8aun0daSS"
   },
   "outputs": [],
   "source": [
    "pip freeze ->requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN16ix3ndu0L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPM4kqK1f5zZ9hw0GJbWIyI",
   "gpuType": "T4",
   "mount_file_id": "1rNpGCVIwQikrlo6Joyxb4oAF8bUoSMMx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
